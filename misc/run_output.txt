=== GPT-2 Training Script (C++ Implementation) ===
Configuration:
  V: 50304
  T: 1024
  C: 768
  n_layers: 6
  B =8, T =1024
  global_batch: 65536
  grad_accum_steps: 8





 rank = 0





=== GPT-2 Training Script (C++ Implementation) ===





 rank = 1






Initializing model on CUDA device 0...


 shape = [ 25152 , 768 ] 


 size = 19316736 rank =  0 name = DEmbeddingVParallel_weight


 shape = [ 25152 , 768 ] 


 size = 19316736 rank =  1 name = DEmbeddingVParallel_weight


 shape = [ 1024 , 768 ] 


 size = 786432 rank =  0 name = DEmbedding_weight
default DTensor contructor :  size = 0 rank =  0
default DTensor contructor :  size = 0 rank =  0
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = DColumnLinear_weight


 shape = [ 1024 , 768 ] 


 size = 786432 rank =  1 name = DEmbedding_weight
default DTensor contructor :  size = 0 rank =  0
default DTensor contructor :  size = 0 rank =  0
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  0 name = DColumnLinear_bias


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  1 name = DColumnLinear_bias


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = DRowLinear_weight


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = DRowLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_bias


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_bias
default DTensor contructor :  size = 0 rank =  0
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = DColumnLinear_weight


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  0 name = DColumnLinear_bias


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  1 name = DColumnLinear_bias


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = DRowLinear_weight


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = DRowLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_bias


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_bias
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = full_weight_init
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  0 name = DColumnLinear_bias


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  1 name = DColumnLinear_bias


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = DRowLinear_weight


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = DRowLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_bias


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_bias
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = Input
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = DColumnLinear_weight


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  0 name = DColumnLinear_bias


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  1 name = DColumnLinear_bias


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = DRowLinear_weight


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = DRowLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_bias


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_bias
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = DColumnLinear_weight
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  0 name = DColumnLinear_bias


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  1 name = DColumnLinear_bias


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = DRowLinear_weight


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = DRowLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_bias


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_bias
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = Input
default DTensor contructor :  size = 0 rank =  0


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  0 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = Input


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 768 ] 


 size = 18874368 rank =  1 name = DColumnLinear_weight


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  0 name = DColumnLinear_bias


 shape = [ 8 , 1024 ] 


 size = 25165824 rank =  1 name = DColumnLinear_bias


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  0 name = DRowLinear_weight


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = full_weight_init


 shape = [ 8 , 3072 ] 


 size = 18874368 rank =  1 name = DRowLinear_weight


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_bias


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_bias


 shape = [ 1 , 1024 ] 


 size = 1024 rank =  0 name = PositionIndices


 B = 8




 T = 1024




 C = 768




 Dpos global shape = [ 1 , 1024 ] 




 shape = [ 8 , 1024 ] 


 size = 8192 rank =  0 name = InputIndices
CUDA0


 shape = [ 1 , 1024 ] 


 size = 1024 rank =  1 name = PositionIndices


 B = 8




 T = 1024




 C = 768




 Dpos global shape = [ 1 , 1024 ] 




 shape = [ 8 , 1024 ] 


 size = 8192 rank =  1 name = InputIndices
CUDA1
  [GPT Constructor] weight initializtion done





 Completed 





Number of parameters: 473098752
found 5 shards for split train
found 1 shards for split val

Starting training...
Saving logs to: Training__log272.csv
Val step 0 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  [GPT Constructor] weight initializtion done





 Completed 







 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 2306MB, Free: 9603MB, Tensors: 56


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 2306MB, Free: 9603MB, Tensors: 58
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 2657MB, Free: 9243MB, Tensors: 56


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 2657MB, Free: 9243MB, Tensors: 58
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 2657MB, Free: 9243MB, Tensors: 59
[MEM] After tok+pos add - Used: 2306MB, Free: 9603MB, Tensors: 59


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 2668MB, Free: 9241MB, Tensors: 69
[MEM] After MLP block 0 - Used: 3051MB, Free: 8849MB, Tensors: 69


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 2988MB, Free: 8921MB, Tensors: 79
[MEM] After MLP block 1 - Used: 3403MB, Free: 8497MB, Tensors: 79


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 3340MB, Free: 8569MB, Tensors: 89
[MEM] After MLP block 2 - Used: 3755MB, Free: 8145MB, Tensors: 89


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 3724MB, Free: 8185MB, Tensors: 99
[MEM] After MLP block 3 - Used: 4107MB, Free: 7793MB, Tensors: 99


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4076MB, Free: 7833MB, Tensors: 109
[MEM] After MLP block 4 - Used: 4491MB, Free: 7409MB, Tensors: 109


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4843MB, Free: 7057MB, Tensors: 119
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4843MB, Free: 7057MB, Tensors: 119
[MEM] After MLP block 5 - Used: 4442MB, Free: 7467MB, Tensors: 119
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4442MB, Free: 7467MB, Tensors: 119


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = ln_f_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = ln_f_output
[MEM] After ln_f - Used: 4875MB, Free: 7025MB, Tensors: 124
[MEM] Before lm_head - Used: 4875MB, Free: 7025MB, Tensors: 124
[MEM] After ln_f - Used: 4474MB, Free: 7435MB, Tensors: 124
[MEM] Before lm_head - Used: 4474MB, Free: 7435MB, Tensors: 124


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = logits


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = logits
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 126
  forward done


 shape = [ 8 , 1024 ] 


 size = 8192 rank =  0 name = global_max


 shape = [ 8 , 1024 ] 


 size = 8192 rank =  0 name = global_sum_exp


 shape = [ 8 , 1024 ] 


 size = 8192 rank =  0 name = global_target_logit
[MEM] After lm_head - Used: 5645MB, Free: 6255MB, Tensors: 126


 shape = [ 8 , 1024 ] 


 size = 8192 rank =  1 name = global_max


 shape = [ 8 , 1024 ] 


 size = 8192 rank =  1 name = global_sum_exp


 shape = [ 8 , 1024 ] 


 size = 8192 rank =  1 name = global_target_logit
  cross_entropy done
Val step 1 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 120


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 122
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4553MB, Free: 7347MB, Tensors: 120


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4553MB, Free: 7347MB, Tensors: 122
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 123
[MEM] After tok+pos add - Used: 4585MB, Free: 7315MB, Tensors: 123


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 134
[MEM] After MLP block 0 - Used: 4969MB, Free: 6931MB, Tensors: 134


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 145
[MEM] After MLP block 1 - Used: 5353MB, Free: 6547MB, Tensors: 145


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 156
[MEM] After MLP block 2 - Used: 5737MB, Free: 6163MB, Tensors: 156


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 167
[MEM] After MLP block 3 - Used: 6121MB, Free: 5779MB, Tensors: 167


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 178
[MEM] After MLP block 4 - Used: 6505MB, Free: 5395MB, Tensors: 178


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 122
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 122
[MEM] After MLP block 5 - Used: 5001MB, Free: 6899MB, Tensors: 122
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5001MB, Free: 6899MB, Tensors: 122
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 127
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 127
[MEM] After ln_f - Used: 5001MB, Free: 6899MB, Tensors: 127
[MEM] Before lm_head - Used: 5001MB, Free: 6899MB, Tensors: 127


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 129
  forward done
[MEM] After lm_head - Used: 5769MB, Free: 6131MB, Tensors: 129
  cross_entropy done
Val step 2 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 122


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 124
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4711MB, Free: 7189MB, Tensors: 122


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4711MB, Free: 7189MB, Tensors: 124
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 125
[MEM] After tok+pos add - Used: 4711MB, Free: 7189MB, Tensors: 125


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 136
[MEM] After MLP block 0 - Used: 5031MB, Free: 6869MB, Tensors: 136


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 147
[MEM] After MLP block 1 - Used: 5415MB, Free: 6485MB, Tensors: 147


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 158
[MEM] After MLP block 2 - Used: 5799MB, Free: 6101MB, Tensors: 158


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 169
[MEM] After MLP block 3 - Used: 6183MB, Free: 5717MB, Tensors: 169


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 180
[MEM] After MLP block 4 - Used: 6535MB, Free: 5365MB, Tensors: 180


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 124
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 124
[MEM] After MLP block 5 - Used: 4871MB, Free: 7029MB, Tensors: 124
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4871MB, Free: 7029MB, Tensors: 124
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 129
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 129
[MEM] After ln_f - Used: 4903MB, Free: 6997MB, Tensors: 129
[MEM] Before lm_head - Used: 4903MB, Free: 6997MB, Tensors: 129


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 131
  forward done
[MEM] After lm_head - Used: 5671MB, Free: 6229MB, Tensors: 131
  cross_entropy done
Val step 3 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


 

 Set Data for idx_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 124


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 126
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4551MB, Free: 7349MB, Tensors: 124


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4551MB, Free: 7349MB, Tensors: 126
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 127
[MEM] After tok+pos add - Used: 4583MB, Free: 7317MB, Tensors: 127


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 138
[MEM] After MLP block 0 - Used: 4967MB, Free: 6933MB, Tensors: 138


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 149
[MEM] After MLP block 1 - Used: 5351MB, Free: 6549MB, Tensors: 149


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 160
[MEM] After MLP block 2 - Used: 5735MB, Free: 6165MB, Tensors: 160


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 171
[MEM] After MLP block 3 - Used: 6119MB, Free: 5781MB, Tensors: 171


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 182
[MEM] After MLP block 4 - Used: 6503MB, Free: 5397MB, Tensors: 182


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 126
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 126
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 131
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 131
[MEM] After MLP block 5 - Used: 4999MB, Free: 6901MB, Tensors: 126
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4999MB, Free: 6901MB, Tensors: 126
[MEM] After ln_f - Used: 4999MB, Free: 6901MB, Tensors: 131
[MEM] Before lm_head - Used: 4999MB, Free: 6901MB, Tensors: 131


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 133
  forward done
[MEM] After lm_head - Used: 5767MB, Free: 6133MB, Tensors: 133
  cross_entropy done
Val step 4 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 126


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 128
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4689MB, Free: 7211MB, Tensors: 126


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4689MB, Free: 7211MB, Tensors: 128
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 129
[MEM] After tok+pos add - Used: 4689MB, Free: 7211MB, Tensors: 129


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 140
[MEM] After MLP block 0 - Used: 5009MB, Free: 6891MB, Tensors: 140


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 151
[MEM] After MLP block 1 - Used: 5393MB, Free: 6507MB, Tensors: 151


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 162
[MEM] After MLP block 2 - Used: 5777MB, Free: 6123MB, Tensors: 162


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 173
[MEM] After MLP block 3 - Used: 6161MB, Free: 5739MB, Tensors: 173


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 184
[MEM] After MLP block 4 - Used: 6513MB, Free: 5387MB, Tensors: 184


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 128
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 128
[MEM] After MLP block 5 - Used: 4849MB, Free: 7051MB, Tensors: 128
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4849MB, Free: 7051MB, Tensors: 128
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 133
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 133
[MEM] After ln_f - Used: 4881MB, Free: 7019MB, Tensors: 133
[MEM] Before lm_head - Used: 4881MB, Free: 7019MB, Tensors: 133


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 135
  forward done
[MEM] After lm_head - Used: 5649MB, Free: 6251MB, Tensors: 135
  cross_entropy done
Val step 5 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 128


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 130
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4529MB, Free: 7371MB, Tensors: 128


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4529MB, Free: 7371MB, Tensors: 130
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 131
[MEM] After tok+pos add - Used: 4561MB, Free: 7339MB, Tensors: 131


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 142
[MEM] After MLP block 0 - Used: 4945MB, Free: 6955MB, Tensors: 142


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 153
[MEM] After MLP block 1 - Used: 5329MB, Free: 6571MB, Tensors: 153


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 164
[MEM] After MLP block 2 - Used: 5713MB, Free: 6187MB, Tensors: 164


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 175
[MEM] After MLP block 3 - Used: 6097MB, Free: 5803MB, Tensors: 175


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 186
[MEM] After MLP block 4 - Used: 6481MB, Free: 5419MB, Tensors: 186


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 130
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 130
[MEM] After MLP block 5 - Used: 4977MB, Free: 6923MB, Tensors: 130
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4977MB, Free: 6923MB, Tensors: 130
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 135
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 135
[MEM] After ln_f - Used: 4977MB, Free: 6923MB, Tensors: 135
[MEM] Before lm_head - Used: 4977MB, Free: 6923MB, Tensors: 135


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 137
  forward done
[MEM] After lm_head - Used: 5745MB, Free: 6155MB, Tensors: 137
  cross_entropy done
Val step 6 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 130


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 132
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4688MB, Free: 7212MB, Tensors: 130


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4688MB, Free: 7212MB, Tensors: 132
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 133
[MEM] After tok+pos add - Used: 4688MB, Free: 7212MB, Tensors: 133


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4697MB, Free: 7212MB, Tensors: 144
[MEM] After MLP block 0 - Used: 5008MB, Free: 6892MB, Tensors: 144


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 155
[MEM] After MLP block 1 - Used: 5392MB, Free: 6508MB, Tensors: 155


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 166
[MEM] After MLP block 2 - Used: 5776MB, Free: 6124MB, Tensors: 166


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 177
[MEM] After MLP block 3 - Used: 6160MB, Free: 5740MB, Tensors: 177


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 188
[MEM] After MLP block 4 - Used: 6512MB, Free: 5388MB, Tensors: 188


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 132
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 132
[MEM] After MLP block 5 - Used: 4848MB, Free: 7052MB, Tensors: 132
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4848MB, Free: 7052MB, Tensors: 132
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 137
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 137
[MEM] After ln_f - Used: 4880MB, Free: 7020MB, Tensors: 137
[MEM] Before lm_head - Used: 4880MB, Free: 7020MB, Tensors: 137


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 139
  forward done
[MEM] After lm_head - Used: 5648MB, Free: 6252MB, Tensors: 139
  cross_entropy done
Val step 7 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 132


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 134
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4528MB, Free: 7372MB, Tensors: 132


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4528MB, Free: 7372MB, Tensors: 134
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 135
[MEM] After tok+pos add - Used: 4560MB, Free: 7340MB, Tensors: 135


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 146
[MEM] After MLP block 0 - Used: 4944MB, Free: 6956MB, Tensors: 146


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 157
[MEM] After MLP block 1 - Used: 5328MB, Free: 6572MB, Tensors: 157


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 168
[MEM] After MLP block 2 - Used: 5712MB, Free: 6188MB, Tensors: 168


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 179
[MEM] After MLP block 3 - Used: 6096MB, Free: 5804MB, Tensors: 179


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 190
[MEM] After MLP block 4 - Used: 6480MB, Free: 5420MB, Tensors: 190


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 134
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 134
[MEM] After MLP block 5 - Used: 4976MB, Free: 6924MB, Tensors: 134
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4976MB, Free: 6924MB, Tensors: 134
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 139
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 139
[MEM] After ln_f - Used: 4976MB, Free: 6924MB, Tensors: 139
[MEM] Before lm_head - Used: 4976MB, Free: 6924MB, Tensors: 139


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 141
  forward done
[MEM] After lm_head - Used: 5744MB, Free: 6156MB, Tensors: 141
  cross_entropy done
Val step 8 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 134


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 136
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4688MB, Free: 7212MB, Tensors: 134


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4688MB, Free: 7212MB, Tensors: 136
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 137
[MEM] After tok+pos add - Used: 4688MB, Free: 7212MB, Tensors: 137


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 148
[MEM] After MLP block 0 - Used: 5008MB, Free: 6892MB, Tensors: 148


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 159
[MEM] After MLP block 1 - Used: 5388MB, Free: 6512MB, Tensors: 159


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 170
[MEM] After MLP block 2 - Used: 5772MB, Free: 6128MB, Tensors: 170


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 181
[MEM] After MLP block 3 - Used: 6156MB, Free: 5744MB, Tensors: 181


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 192
[MEM] After MLP block 4 - Used: 6508MB, Free: 5392MB, Tensors: 192


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 136
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 136
[MEM] After MLP block 5 - Used: 4844MB, Free: 7056MB, Tensors: 136
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4844MB, Free: 7056MB, Tensors: 136
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 141
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 141
[MEM] After ln_f - Used: 4876MB, Free: 7024MB, Tensors: 141
[MEM] Before lm_head - Used: 4876MB, Free: 7024MB, Tensors: 141


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 143
  forward done
[MEM] After lm_head - Used: 5644MB, Free: 6256MB, Tensors: 143
  cross_entropy done
Val step 9 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 136


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 138
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4524MB, Free: 7376MB, Tensors: 136


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4524MB, Free: 7376MB, Tensors: 138
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 139
[MEM] After tok+pos add - Used: 4556MB, Free: 7344MB, Tensors: 139


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 150
[MEM] After MLP block 0 - Used: 4940MB, Free: 6960MB, Tensors: 150


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 161
[MEM] After MLP block 1 - Used: 5324MB, Free: 6576MB, Tensors: 161


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 172
[MEM] After MLP block 2 - Used: 5708MB, Free: 6192MB, Tensors: 172


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 183
[MEM] After MLP block 3 - Used: 6092MB, Free: 5808MB, Tensors: 183


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 194
[MEM] After MLP block 4 - Used: 6476MB, Free: 5424MB, Tensors: 194


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 138
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 138
[MEM] After MLP block 5 - Used: 4968MB, Free: 6932MB, Tensors: 138
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4968MB, Free: 6932MB, Tensors: 138
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 143
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 143
[MEM] After ln_f - Used: 4968MB, Free: 6932MB, Tensors: 143
[MEM] Before lm_head - Used: 4968MB, Free: 6932MB, Tensors: 143


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 145
  forward done
[MEM] After lm_head - Used: 5736MB, Free: 6164MB, Tensors: 145
  cross_entropy done
Val step 10 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 138


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 140
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4680MB, Free: 7220MB, Tensors: 138


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4680MB, Free: 7220MB, Tensors: 140
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 141
[MEM] After tok+pos add - Used: 4680MB, Free: 7220MB, Tensors: 141


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 152
[MEM] After MLP block 0 - Used: 5000MB, Free: 6900MB, Tensors: 152


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 163
[MEM] After MLP block 1 - Used: 5384MB, Free: 6516MB, Tensors: 163


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 174
[MEM] After MLP block 2 - Used: 5768MB, Free: 6132MB, Tensors: 174


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 185
[MEM] After MLP block 3 - Used: 6152MB, Free: 5748MB, Tensors: 185


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 196
[MEM] After MLP block 4 - Used: 6504MB, Free: 5396MB, Tensors: 196


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 140
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 140
[MEM] After MLP block 5 - Used: 4840MB, Free: 7060MB, Tensors: 140
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4840MB, Free: 7060MB, Tensors: 140
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 145
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 145
[MEM] After ln_f - Used: 4872MB, Free: 7028MB, Tensors: 145
[MEM] Before lm_head - Used: 4872MB, Free: 7028MB, Tensors: 145


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 147
  forward done
[MEM] After lm_head - Used: 5640MB, Free: 6260MB, Tensors: 147
  cross_entropy done
Val step 11 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 140


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 142
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4514MB, Free: 7386MB, Tensors: 140


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4514MB, Free: 7386MB, Tensors: 142
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 143
[MEM] After tok+pos add - Used: 4546MB, Free: 7354MB, Tensors: 143


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 154
[MEM] After MLP block 0 - Used: 4930MB, Free: 6970MB, Tensors: 154


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 165
[MEM] After MLP block 1 - Used: 5314MB, Free: 6586MB, Tensors: 165


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 176
[MEM] After MLP block 2 - Used: 5698MB, Free: 6202MB, Tensors: 176


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 187
[MEM] After MLP block 3 - Used: 6082MB, Free: 5818MB, Tensors: 187


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 198
[MEM] After MLP block 4 - Used: 6466MB, Free: 5434MB, Tensors: 198


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 142
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 142
[MEM] After MLP block 5 - Used: 4962MB, Free: 6938MB, Tensors: 142
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4962MB, Free: 6938MB, Tensors: 142
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 147
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 147
[MEM] After ln_f - Used: 4962MB, Free: 6938MB, Tensors: 147
[MEM] Before lm_head - Used: 4962MB, Free: 6938MB, Tensors: 147


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 149
  forward done
[MEM] After lm_head - Used: 5730MB, Free: 6170MB, Tensors: 149
  cross_entropy done
Val step 12 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 142


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 144
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4674MB, Free: 7226MB, Tensors: 142


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4674MB, Free: 7226MB, Tensors: 144
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 145
[MEM] After tok+pos add - Used: 4674MB, Free: 7226MB, Tensors: 145


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4697MB, Free: 7212MB, Tensors: 156
[MEM] After MLP block 0 - Used: 4994MB, Free: 6906MB, Tensors: 156


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 167
[MEM] After MLP block 1 - Used: 5378MB, Free: 6522MB, Tensors: 167


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 178
[MEM] After MLP block 2 - Used: 5762MB, Free: 6138MB, Tensors: 178


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 189
[MEM] After MLP block 3 - Used: 6146MB, Free: 5754MB, Tensors: 189


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 200
[MEM] After MLP block 4 - Used: 6498MB, Free: 5402MB, Tensors: 200


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 144
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 144
[MEM] After MLP block 5 - Used: 4834MB, Free: 7066MB, Tensors: 144
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4834MB, Free: 7066MB, Tensors: 144
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 149
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 149
[MEM] After ln_f - Used: 4866MB, Free: 7034MB, Tensors: 149
[MEM] Before lm_head - Used: 4866MB, Free: 7034MB, Tensors: 149


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 151
  forward done
[MEM] After lm_head - Used: 5634MB, Free: 6266MB, Tensors: 151
  cross_entropy done
Val step 13 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 144


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 146
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4510MB, Free: 7390MB, Tensors: 144


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4510MB, Free: 7390MB, Tensors: 146
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 147
[MEM] After tok+pos add - Used: 4542MB, Free: 7358MB, Tensors: 147


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 158
[MEM] After MLP block 0 - Used: 4926MB, Free: 6974MB, Tensors: 158


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 169
[MEM] After MLP block 1 - Used: 5310MB, Free: 6590MB, Tensors: 169


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 180
[MEM] After MLP block 2 - Used: 5694MB, Free: 6206MB, Tensors: 180


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 191
[MEM] After MLP block 3 - Used: 6078MB, Free: 5822MB, Tensors: 191


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 202
[MEM] After MLP block 4 - Used: 6462MB, Free: 5438MB, Tensors: 202


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 146
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 146
[MEM] After MLP block 5 - Used: 4958MB, Free: 6942MB, Tensors: 146
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4958MB, Free: 6942MB, Tensors: 146
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 151
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 151
[MEM] After ln_f - Used: 4958MB, Free: 6942MB, Tensors: 151
[MEM] Before lm_head - Used: 4958MB, Free: 6942MB, Tensors: 151


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 153
  forward done
[MEM] After lm_head - Used: 5726MB, Free: 6174MB, Tensors: 153
  cross_entropy done
Val step 14 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 146


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 148
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4670MB, Free: 7230MB, Tensors: 146


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4670MB, Free: 7230MB, Tensors: 148
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 149
[MEM] After tok+pos add - Used: 4670MB, Free: 7230MB, Tensors: 149


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 160
[MEM] After MLP block 0 - Used: 4990MB, Free: 6910MB, Tensors: 160


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 171
[MEM] After MLP block 1 - Used: 5374MB, Free: 6526MB, Tensors: 171


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 182
[MEM] After MLP block 2 - Used: 5758MB, Free: 6142MB, Tensors: 182


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 193
[MEM] After MLP block 3 - Used: 6142MB, Free: 5758MB, Tensors: 193


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 204
[MEM] After MLP block 4 - Used: 6494MB, Free: 5406MB, Tensors: 204


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 148
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 148
[MEM] After MLP block 5 - Used: 4830MB, Free: 7070MB, Tensors: 148
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4830MB, Free: 7070MB, Tensors: 148
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 153
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 153
[MEM] After ln_f - Used: 4862MB, Free: 7038MB, Tensors: 153
[MEM] Before lm_head - Used: 4862MB, Free: 7038MB, Tensors: 153


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 155
  forward done
[MEM] After lm_head - Used: 5630MB, Free: 6270MB, Tensors: 155
  cross_entropy done
Val step 15 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 148


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 150
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4510MB, Free: 7390MB, Tensors: 148


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4510MB, Free: 7390MB, Tensors: 150
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 151
[MEM] After tok+pos add - Used: 4542MB, Free: 7358MB, Tensors: 151


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 162
[MEM] After MLP block 0 - Used: 4926MB, Free: 6974MB, Tensors: 162


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 173
[MEM] After MLP block 1 - Used: 5310MB, Free: 6590MB, Tensors: 173


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 184
[MEM] After MLP block 2 - Used: 5694MB, Free: 6206MB, Tensors: 184


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 195
[MEM] After MLP block 3 - Used: 6078MB, Free: 5822MB, Tensors: 195


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 206
[MEM] After MLP block 4 - Used: 6462MB, Free: 5438MB, Tensors: 206


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 150
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 150
[MEM] After MLP block 5 - Used: 4958MB, Free: 6942MB, Tensors: 150
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4958MB, Free: 6942MB, Tensors: 150
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 155
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 155
[MEM] After ln_f - Used: 4958MB, Free: 6942MB, Tensors: 155
[MEM] Before lm_head - Used: 4958MB, Free: 6942MB, Tensors: 155


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 157
  forward done
[MEM] After lm_head - Used: 5726MB, Free: 6174MB, Tensors: 157
  cross_entropy done
Val step 16 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 150


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 152
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4670MB, Free: 7230MB, Tensors: 150


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4670MB, Free: 7230MB, Tensors: 152
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 153
[MEM] After tok+pos add - Used: 4670MB, Free: 7230MB, Tensors: 153


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 164
[MEM] After MLP block 0 - Used: 4990MB, Free: 6910MB, Tensors: 164


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 175
[MEM] After MLP block 1 - Used: 5374MB, Free: 6526MB, Tensors: 175


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 186
[MEM] After MLP block 2 - Used: 5758MB, Free: 6142MB, Tensors: 186


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 197
[MEM] After MLP block 3 - Used: 6142MB, Free: 5758MB, Tensors: 197


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 208
[MEM] After MLP block 4 - Used: 6494MB, Free: 5406MB, Tensors: 208


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 152
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 152
[MEM] After MLP block 5 - Used: 4830MB, Free: 7070MB, Tensors: 152
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4830MB, Free: 7070MB, Tensors: 152
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 157
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 157
[MEM] After ln_f - Used: 4862MB, Free: 7038MB, Tensors: 157
[MEM] Before lm_head - Used: 4862MB, Free: 7038MB, Tensors: 157


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5630MB, Free: 6270MB, Tensors: 159
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 159
  forward done
  cross_entropy done
Val step 17 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 152


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 154
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4510MB, Free: 7390MB, Tensors: 152


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4510MB, Free: 7390MB, Tensors: 154
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 155
[MEM] After tok+pos add - Used: 4542MB, Free: 7358MB, Tensors: 155


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 166
[MEM] After MLP block 0 - Used: 4926MB, Free: 6974MB, Tensors: 166


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 177
[MEM] After MLP block 1 - Used: 5310MB, Free: 6590MB, Tensors: 177


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 188
[MEM] After MLP block 2 - Used: 5694MB, Free: 6206MB, Tensors: 188


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 199
[MEM] After MLP block 3 - Used: 6078MB, Free: 5822MB, Tensors: 199


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 210
[MEM] After MLP block 4 - Used: 6462MB, Free: 5438MB, Tensors: 210


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 154
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 154
[MEM] After MLP block 5 - Used: 4958MB, Free: 6942MB, Tensors: 154
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4958MB, Free: 6942MB, Tensors: 154
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 159
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 159
[MEM] After ln_f - Used: 4958MB, Free: 6942MB, Tensors: 159
[MEM] Before lm_head - Used: 4958MB, Free: 6942MB, Tensors: 159


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 161
  forward done
[MEM] After lm_head - Used: 5726MB, Free: 6174MB, Tensors: 161
  cross_entropy done
Val step 18 - starting
  batch loaded


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 154


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 156
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4675MB, Free: 7225MB, Tensors: 154


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4675MB, Free: 7225MB, Tensors: 156
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 157
[MEM] After tok+pos add - Used: 4675MB, Free: 7225MB, Tensors: 157


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4697MB, Free: 7212MB, Tensors: 168
[MEM] After MLP block 0 - Used: 4995MB, Free: 6905MB, Tensors: 168


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 179
[MEM] After MLP block 1 - Used: 5379MB, Free: 6521MB, Tensors: 179


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 190
[MEM] After MLP block 2 - Used: 5763MB, Free: 6137MB, Tensors: 190


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 201
[MEM] After MLP block 3 - Used: 6147MB, Free: 5753MB, Tensors: 201


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 212
[MEM] After MLP block 4 - Used: 6499MB, Free: 5401MB, Tensors: 212


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 156
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 156
[MEM] After MLP block 5 - Used: 4835MB, Free: 7065MB, Tensors: 156
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4835MB, Free: 7065MB, Tensors: 156
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 161
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 161
[MEM] After ln_f - Used: 4867MB, Free: 7033MB, Tensors: 161
[MEM] Before lm_head - Used: 4867MB, Free: 7033MB, Tensors: 161


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 163
  forward done
[MEM] After lm_head - Used: 5635MB, Free: 6265MB, Tensors: 163
  cross_entropy done
Val step 19 - starting
  batch loaded
  x.to done
  y.to done


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4217MB, Free: 7692MB, Tensors: 156


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4217MB, Free: 7692MB, Tensors: 158
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4515MB, Free: 7385MB, Tensors: 156


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4515MB, Free: 7385MB, Tensors: 158
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4249MB, Free: 7660MB, Tensors: 159
[MEM] After tok+pos add - Used: 4547MB, Free: 7353MB, Tensors: 159


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4633MB, Free: 7276MB, Tensors: 170
[MEM] After MLP block 0 - Used: 4931MB, Free: 6969MB, Tensors: 170


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5017MB, Free: 6892MB, Tensors: 181
[MEM] After MLP block 1 - Used: 5315MB, Free: 6585MB, Tensors: 181


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5401MB, Free: 6508MB, Tensors: 192
[MEM] After MLP block 2 - Used: 5699MB, Free: 6201MB, Tensors: 192


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5785MB, Free: 6124MB, Tensors: 203
[MEM] After MLP block 3 - Used: 6083MB, Free: 5817MB, Tensors: 203


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6169MB, Free: 5740MB, Tensors: 214
[MEM] After MLP block 4 - Used: 6467MB, Free: 5433MB, Tensors: 214


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4633MB, Free: 7276MB, Tensors: 158
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4633MB, Free: 7276MB, Tensors: 158
[MEM] After MLP block 5 - Used: 4963MB, Free: 6937MB, Tensors: 158
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4963MB, Free: 6937MB, Tensors: 158
[MEM] After ln_f - Used: 4665MB, Free: 7244MB, Tensors: 163
[MEM] Before lm_head - Used: 4665MB, Free: 7244MB, Tensors: 163
[MEM] After ln_f - Used: 4963MB, Free: 6937MB, Tensors: 163
[MEM] Before lm_head - Used: 4963MB, Free: 6937MB, Tensors: 163


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5433MB, Free: 6476MB, Tensors: 165
  forward done
[MEM] After lm_head - Used: 5731MB, Free: 6169MB, Tensors: 165
  cross_entropy done
validation loss: 10.8258

 microstep = 0

 microstep = 0
[MEM] Start of micro_step 0 - Used: 4675MB, Free: 7225MB, Tensors: 151


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] Start of micro_step 0 - Used: 4345MB, Free: 7564MB, Tensors: 151


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4345MB, Free: 7564MB, Tensors: 159


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 4345MB, Free: 7564MB, Tensors: 161
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 4675MB, Free: 7225MB, Tensors: 159


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 4675MB, Free: 7225MB, Tensors: 161
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 4345MB, Free: 7564MB, Tensors: 162
[MEM] After tok+pos add - Used: 4675MB, Free: 7225MB, Tensors: 162


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 4729MB, Free: 7180MB, Tensors: 173
[MEM] After MLP block 0 - Used: 4994MB, Free: 6905MB, Tensors: 173


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 5081MB, Free: 6828MB, Tensors: 184
[MEM] After MLP block 1 - Used: 5378MB, Free: 6521MB, Tensors: 184


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 5433MB, Free: 6476MB, Tensors: 195
[MEM] After MLP block 2 - Used: 5762MB, Free: 6137MB, Tensors: 195


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 5817MB, Free: 6092MB, Tensors: 206
[MEM] After MLP block 3 - Used: 6146MB, Free: 5753MB, Tensors: 206


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 6201MB, Free: 5708MB, Tensors: 217
[MEM] After MLP block 4 - Used: 6498MB, Free: 5401MB, Tensors: 217


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 4537MB, Free: 7372MB, Tensors: 161
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4537MB, Free: 7372MB, Tensors: 161
[MEM] After MLP block 5 - Used: 4834MB, Free: 7065MB, Tensors: 161
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 4834MB, Free: 7065MB, Tensors: 161
[MEM] After ln_f - Used: 4569MB, Free: 7340MB, Tensors: 166
[MEM] Before lm_head - Used: 4569MB, Free: 7340MB, Tensors: 166
[MEM] After ln_f - Used: 4866MB, Free: 7033MB, Tensors: 166
[MEM] Before lm_head - Used: 4866MB, Free: 7033MB, Tensors: 166


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 5634MB, Free: 6265MB, Tensors: 168
[MEM] After lm_head - Used: 5337MB, Free: 6572MB, Tensors: 168
[MEM] After backward, before release - Used: 4345MB, Free: 7564MB, Tensors: 120
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4579MB, Free: 7321MB, Tensors: 120
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3651MB, Free: 8249MB, Tensors: 108
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (108 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: [MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 108
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (108 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | AuTensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
tograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
==========================================


 microstep = 1
[MEM] Start of micro_step 1 - Used: 3651MB, Free: 8249MB, Tensors: 108


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99792f10 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 1
[MEM] Start of micro_step 1 - Used: 3321MB, Free: 8588MB, Tensors: 108


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 116


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 118
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3651MB, Free: 8249MB, Tensors: 116


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3651MB, Free: 8249MB, Tensors: 118
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 119
[MEM] After tok+pos add - Used: 3651MB, Free: 8249MB, Tensors: 119


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 130
[MEM] After MLP block 0 - Used: 3907MB, Free: 7993MB, Tensors: 130


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 141
[MEM] After MLP block 1 - Used: 4227MB, Free: 7673MB, Tensors: 141


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 152
[MEM] After MLP block 2 - Used: 4547MB, Free: 7353MB, Tensors: 152


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4569MB, Free: 7340MB, Tensors: 163
[MEM] After MLP block 3 - Used: 4835MB, Free: 7065MB, Tensors: 163


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4921MB, Free: 6988MB, Tensors: 174
[MEM] After MLP block 4 - Used: 5187MB, Free: 6713MB, Tensors: 174


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 185
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 185
[MEM] After MLP block 5 - Used: 5539MB, Free: 6361MB, Tensors: 185
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5539MB, Free: 6361MB, Tensors: 185
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 190
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 190
[MEM] After ln_f - Used: 5571MB, Free: 6329MB, Tensors: 190
[MEM] Before lm_head - Used: 5571MB, Free: 6329MB, Tensors: 190


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 192
[MEM] After lm_head - Used: 6339MB, Free: 5561MB, Tensors: 192
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 122
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4610MB, Free: 7289MB, Tensors: 122
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 110
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (110 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc49d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 2
[MEM] Start of micro_step 2 - Used: 3321MB, Free: 8588MB, Tensors: 110


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] After all releases - Used: 3650MB, Free: 8249MB, Tensors: 110
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (110 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e974a7e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1ebb0e300 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 2
[MEM] Start of micro_step 2 - Used: 3650MB, Free: 8249MB, Tensors: 110


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 118


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 120
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3650MB, Free: 8249MB, Tensors: 118


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3650MB, Free: 8249MB, Tensors: 120
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 121
[MEM] After tok+pos add - Used: 3650MB, Free: 8249MB, Tensors: 121


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 132
[MEM] After MLP block 0 - Used: 3906MB, Free: 7993MB, Tensors: 132


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 143
[MEM] After MLP block 1 - Used: 4226MB, Free: 7673MB, Tensors: 143


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 154
[MEM] After MLP block 2 - Used: 4546MB, Free: 7353MB, Tensors: 154


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4537MB, Free: 7372MB, Tensors: 165
[MEM] After MLP block 3 - Used: 4834MB, Free: 7065MB, Tensors: 165


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4921MB, Free: 6988MB, Tensors: 176
[MEM] After MLP block 4 - Used: 5186MB, Free: 6713MB, Tensors: 176


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 187
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 187
[MEM] After MLP block 5 - Used: 5538MB, Free: 6361MB, Tensors: 187
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5538MB, Free: 6361MB, Tensors: 187
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 192
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 192
[MEM] After ln_f - Used: 5570MB, Free: 6329MB, Tensors: 192
[MEM] Before lm_head - Used: 5570MB, Free: 6329MB, Tensors: 192


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 194
[MEM] After lm_head - Used: 6338MB, Free: 5561MB, Tensors: 194
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 124
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4610MB, Free: 7289MB, Tensors: 124
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 112
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (112 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc9f60 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dcc6c0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de5ab0 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 3
[MEM] Start of micro_step 3 - Used: 3321MB, Free: 8588MB, Tensors: 112


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] After all releases - Used: 3650MB, Free: 8249MB, Tensors: 112
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (112 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e97549d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1ebb00ef0 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb01b90 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0e300 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 3
[MEM] Start of micro_step 3 - Used: 3650MB, Free: 8249MB, Tensors: 112


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 120


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 122
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3650MB, Free: 8249MB, Tensors: 120


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3650MB, Free: 8249MB, Tensors: 122
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 123
[MEM] After tok+pos add - Used: 3650MB, Free: 8249MB, Tensors: 123


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 134
[MEM] After MLP block 0 - Used: 3906MB, Free: 7993MB, Tensors: 134


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 145
[MEM] After MLP block 1 - Used: 4226MB, Free: 7673MB, Tensors: 145


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 156
[MEM] After MLP block 2 - Used: 4546MB, Free: 7353MB, Tensors: 156


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4569MB, Free: 7340MB, Tensors: 167
[MEM] After MLP block 3 - Used: 4834MB, Free: 7065MB, Tensors: 167


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4889MB, Free: 7020MB, Tensors: 178
[MEM] After MLP block 4 - Used: 5186MB, Free: 6713MB, Tensors: 178


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 189
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 189
[MEM] After MLP block 5 - Used: 5538MB, Free: 6361MB, Tensors: 189
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5538MB, Free: 6361MB, Tensors: 189
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 194
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 194
[MEM] After ln_f - Used: 5570MB, Free: 6329MB, Tensors: 194
[MEM] Before lm_head - Used: 5570MB, Free: 6329MB, Tensors: 194


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 196
[MEM] After lm_head - Used: 6338MB, Free: 5561MB, Tensors: 196
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 126
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4610MB, Free: 7289MB, Tensors: 126
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 114
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (114 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc9f60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de5ab0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d74470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c99d7af80 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7bc20 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 4
[MEM] Start of micro_step 4 - Used: 3321MB, Free: 8588MB, Tensors: 114


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] After all releases - Used: 3650MB, Free: 8249MB, Tensors: 114
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (114 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1ead40600 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1ebb00ef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb01b90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb04280 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb05bc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1ebb0e300 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 4
[MEM] Start of micro_step 4 - Used: 3650MB, Free: 8249MB, Tensors: 114


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 122


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 124
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3650MB, Free: 8249MB, Tensors: 122


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3650MB, Free: 8249MB, Tensors: 124
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 125
[MEM] After tok+pos add - Used: 3650MB, Free: 8249MB, Tensors: 125


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 136
[MEM] After MLP block 0 - Used: 3906MB, Free: 7993MB, Tensors: 136


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 147
[MEM] After MLP block 1 - Used: 4226MB, Free: 7673MB, Tensors: 147


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 158
[MEM] After MLP block 2 - Used: 4546MB, Free: 7353MB, Tensors: 158


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4569MB, Free: 7340MB, Tensors: 169
[MEM] After MLP block 3 - Used: 4834MB, Free: 7065MB, Tensors: 169


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4921MB, Free: 6988MB, Tensors: 180
[MEM] After MLP block 4 - Used: 5187MB, Free: 6713MB, Tensors: 180


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 191
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 191
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 196
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 196
[MEM] After MLP block 5 - Used: 5539MB, Free: 6361MB, Tensors: 191
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5539MB, Free: 6361MB, Tensors: 191
[MEM] After ln_f - Used: 5576MB, Free: 6324MB, Tensors: 196
[MEM] Before lm_head - Used: 5576MB, Free: 6324MB, Tensors: 196


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 198
[MEM] After lm_head - Used: 6346MB, Free: 5554MB, Tensors: 198
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 128
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4618MB, Free: 7282MB, Tensors: 128
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 116
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (116 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc9f60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de5ab0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d6fb30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c99d7af80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7bc20 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7f540 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d801e0 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 5
[MEM] Start of micro_step 5 - Used: 3321MB, Free: 8588MB, Tensors: 116


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] After all releases - Used: 3658MB, Free: 8242MB, Tensors: 116
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (116 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e545c580 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e974fab0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1ead40600 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1eb6eb160 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb00ef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb01b90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb04280 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0e300 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 5
[MEM] Start of micro_step 5 - Used: 3658MB, Free: 8242MB, Tensors: 116


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 124


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 126
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3658MB, Free: 8242MB, Tensors: 124


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3658MB, Free: 8242MB, Tensors: 126
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 127
[MEM] After tok+pos add - Used: 3658MB, Free: 8242MB, Tensors: 127


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 138
[MEM] After MLP block 0 - Used: 3914MB, Free: 7986MB, Tensors: 138


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 149
[MEM] After MLP block 1 - Used: 4234MB, Free: 7666MB, Tensors: 149


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 160
[MEM] After MLP block 2 - Used: 4554MB, Free: 7346MB, Tensors: 160


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4569MB, Free: 7340MB, Tensors: 171
[MEM] After MLP block 3 - Used: 4842MB, Free: 7058MB, Tensors: 171


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4921MB, Free: 6988MB, Tensors: 182
[MEM] After MLP block 4 - Used: 5194MB, Free: 6706MB, Tensors: 182


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 193
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 193
[MEM] After MLP block 5 - Used: 5546MB, Free: 6354MB, Tensors: 193
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5546MB, Free: 6354MB, Tensors: 193
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 198
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 198
[MEM] After ln_f - Used: 5578MB, Free: 6322MB, Tensors: 198
[MEM] Before lm_head - Used: 5578MB, Free: 6322MB, Tensors: 198


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 200
[MEM] After lm_head - Used: 6346MB, Free: 5554MB, Tensors: 200
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 130
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4616MB, Free: 7284MB, Tensors: 130
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 118
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (118 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc9f60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de5ab0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9978dd50 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7af80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7bc20 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7f540 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d801e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a60f0 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a6d90 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 6
[MEM] Start of micro_step 6 - Used: 3321MB, Free: 8588MB, Tensors: 118


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] After all releases - Used: 3656MB, Free: 8244MB, Tensors: 118
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (118 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e545c580 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9740da0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1ead40600 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1eb6df9f0 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6e0690 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6eb160 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb00ef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb01b90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb04280 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0e300 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 6
[MEM] Start of micro_step 6 - Used: 3656MB, Free: 8244MB, Tensors: 118


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 126


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 128
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3656MB, Free: 8244MB, Tensors: 126


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3656MB, Free: 8244MB, Tensors: 128
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 129
[MEM] After tok+pos add - Used: 3656MB, Free: 8244MB, Tensors: 129


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 140
[MEM] After MLP block 0 - Used: 3912MB, Free: 7988MB, Tensors: 140


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 151
[MEM] After MLP block 1 - Used: 4232MB, Free: 7668MB, Tensors: 151


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 162
[MEM] After MLP block 2 - Used: 4552MB, Free: 7348MB, Tensors: 162


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4537MB, Free: 7372MB, Tensors: 173
[MEM] After MLP block 3 - Used: 4840MB, Free: 7060MB, Tensors: 173


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4921MB, Free: 6988MB, Tensors: 184
[MEM] After MLP block 4 - Used: 5192MB, Free: 6708MB, Tensors: 184


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 195
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 195
[MEM] After MLP block 5 - Used: 5544MB, Free: 6356MB, Tensors: 195
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5544MB, Free: 6356MB, Tensors: 195
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 200
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 200
[MEM] After ln_f - Used: 5576MB, Free: 6324MB, Tensors: 200
[MEM] Before lm_head - Used: 5576MB, Free: 6324MB, Tensors: 200


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 202
[MEM] After lm_head - Used: 6344MB, Free: 5556MB, Tensors: 202
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 132
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4615MB, Free: 7285MB, Tensors: 132
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 120
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (120 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc9f60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de5ab0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9978a110 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7af80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7bc20 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7f540 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d801e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3a60 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a4700 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a60f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a6d90 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 7
[MEM] Start of micro_step 7 - Used: 3321MB, Free: 8588MB, Tensors: 120


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 


[MEM] After all releases - Used: 3655MB, Free: 8245MB, Tensors: 120
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (120 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e545c580 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9769f00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1ead39fe0 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead40600 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1eb6dcc20 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6df9f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6e0690 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6eb160 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb00ef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb01b90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb04280 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0e300 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================


 microstep = 7
[MEM] Start of micro_step 7 - Used: 3655MB, Free: 8245MB, Tensors: 120


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3321MB, Free: 8588MB, Tensors: 128


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 3321MB, Free: 8588MB, Tensors: 130
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 3655MB, Free: 8245MB, Tensors: 128


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 3655MB, Free: 8245MB, Tensors: 130
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 3321MB, Free: 8588MB, Tensors: 131
[MEM] After tok+pos add - Used: 3655MB, Free: 8245MB, Tensors: 131


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 3609MB, Free: 8300MB, Tensors: 142
[MEM] After MLP block 0 - Used: 3911MB, Free: 7989MB, Tensors: 142


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 3929MB, Free: 7980MB, Tensors: 153
[MEM] After MLP block 1 - Used: 4231MB, Free: 7669MB, Tensors: 153


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 4249MB, Free: 7660MB, Tensors: 164
[MEM] After MLP block 2 - Used: 4551MB, Free: 7349MB, Tensors: 164


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 4569MB, Free: 7340MB, Tensors: 175
[MEM] After MLP block 3 - Used: 4839MB, Free: 7061MB, Tensors: 175


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 4889MB, Free: 7020MB, Tensors: 186
[MEM] After MLP block 4 - Used: 5191MB, Free: 6709MB, Tensors: 186


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 5241MB, Free: 6668MB, Tensors: 197
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5241MB, Free: 6668MB, Tensors: 197
[MEM] After MLP block 5 - Used: 5543MB, Free: 6357MB, Tensors: 197
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 5543MB, Free: 6357MB, Tensors: 197
[MEM] After ln_f - Used: 5273MB, Free: 6636MB, Tensors: 202
[MEM] Before lm_head - Used: 5273MB, Free: 6636MB, Tensors: 202
[MEM] After ln_f - Used: 5575MB, Free: 6325MB, Tensors: 202
[MEM] Before lm_head - Used: 5575MB, Free: 6325MB, Tensors: 202


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 6073MB, Free: 5836MB, Tensors: 204
[MEM] After lm_head - Used: 6343MB, Free: 5557MB, Tensors: 204
[MEM] After backward, before release - Used: 4281MB, Free: 7628MB, Tensors: 134
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After backward, before release - Used: 4614MB, Free: 7286MB, Tensors: 134
=== REFCOUNTS BEFORE RELEASE ===
[REFCOUNT] loss: impl=1, storage=1
[REFCOUNT] grad_scale: impl=1, storage=1
[REFCOUNT] batch.input (x): impl=1, storage=1
[REFCOUNT] batch.target (y): impl=1, storage=1
[REFCOUNT] model.logits: impl=1, storage=1
[REFCOUNT] model.y: impl=1, storage=1
[MEM] After all releases - Used: 3321MB, Free: 8588MB, Tensors: 122
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (122 tensors) ===
Tensor 0x624c8fca9170 | Refcount: 1 | Device: 0 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x624c903938d0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x624c90ae0af0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0ed0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae0f70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae1540 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90ae4340 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c90ae7220 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90ae9480 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b3ce30 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b3f100 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b40290 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b40e70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b41c10 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b49a20 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b4bce0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b4c140 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b4de40 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b4ea70 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b51fd0 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b53b90 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b55e80 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b561c0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b580a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b597d0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5b510 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b5db50 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b5fe40 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b5ff90 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b62020 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b62850 | Refcount: 1 | Device: 0 | Shape: [8,1024] | Autograd: None | 
Tensor 0x624c90b62c50 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b66120 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b67ce0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b69fd0 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b6bb80 | Refcount: 1 | Device: 0 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x624c90b6c110 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b6d170 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b6d7e0 | Refcount: 2 | Device: 0 | Shape: [768] | GradFn: None/Null | 
Tensor 0x624c90b70e30 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x624c90b73120 | Refcount: 1 | Device: 0 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x624c90b75260 | Refcount: 1 | Device: 0 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x624c90b75e70 | Refcount: 1 | Device: 0 | Shape: [1,1024] | Autograd: None | 
Tensor 0x624c90b81480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c90b82bb0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aee420 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c93aef400 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c93aef710 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d20590 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97d22890 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97db8c30 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbcb80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbe4a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf350 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dbf470 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc07f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc0b70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc1a50 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dc2c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc7150 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dc7250 | Refcount: 6 | Device: 0 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x624c97dc9130 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c97dc9f60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcb7a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x624c97dcbb60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dcc1f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd0100 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dd08d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd22a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dd89b0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dde640 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97ddf020 | Refcount: 1 | Device: 0 | Shape: [1] | Autograd: None | 
Tensor 0x624c97de3880 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de3e80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97de5ab0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97deb9e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df5db0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df8c70 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97df9140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfc2a0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfd390 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97dfda70 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c97dfee40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e00cf0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c97e22190 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bd5c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993bd740 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993beaa0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993bf0c0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c993c2610 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cbec0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993cc5a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x624c993cc730 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c993ce420 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99784280 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99786b00 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99788200 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99788810 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99791aa0 | Refcount: 1 | Device: 0 | Shape: [1024,768] | Autograd: None | 
Tensor 0x624c99d4ea40 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d4f480 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f410 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d5f830 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d612a0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d62800 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d64140 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66180 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d66ea0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d672f0 | Refcount: 1 | Device: 0 | Shape: [768] | Autograd: None | 
Tensor 0x624c99d6a920 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7af80 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7bc20 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d7f540 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c99d801e0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a19e9c0 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a19f660 | Refcount: 2 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a27d0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3470 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a3a60 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a4700 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a60f0 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x624c9a1a6d90 | Refcount: 1 | Device: 0 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================

[MEM] After all releases - Used: 3654MB, Free: 8246MB, Tensors: 122
=== FULL ACTIVE TENSOR REGISTRY ===

=== ACTIVE TENSOR REGISTRY (122 tensors) ===
Tensor 0x61f1dd9193e0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d2cf90 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e1d3f810 | Refcount: 1 | Device: 1 | Shape: [1024,768] | GradFn: None/Null | 
Tensor 0x61f1e248c070 | Refcount: 1 | Device: 1 | Shape: [25152,768] | GradFn: None/Null | 
Tensor 0x61f1e248e9f0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e248ea70 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491280 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2491cb0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24929c0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e2493e10 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24964f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24ab190 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24acef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24aefe0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b3020 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24b4430 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b5ff0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24b8630 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24baf40 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24bb810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24bcc40 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24be770 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c02e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c2960 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24c2ac0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c4770 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24c4ed0 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24c7230 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24c8df0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24cb590 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cd1c0 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24ce330 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24cf7e0 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24d17b0 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d3dc0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24d8190 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24d9300 | Refcount: 2 | Device: 1 | Shape: [768] | GradFn: None/Null | 
Tensor 0x61f1e24d9600 | Refcount: 1 | Device: 1 | Shape: [8,1024] | Autograd: None | 
Tensor 0x61f1e24db260 | Refcount: 1 | Device: 1 | Shape: [8,768,3072] | GradFn: None/Null | 
Tensor 0x61f1e24dcdd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | GradFn: None/Null | 
Tensor 0x61f1e24df450 | Refcount: 1 | Device: 1 | Shape: [8,3072,768] | GradFn: None/Null | 
Tensor 0x61f1e24e1d60 | Refcount: 1 | Device: 1 | Shape: [8,1024,768] | GradFn: None/Null | 
Tensor 0x61f1e24e24c0 | Refcount: 1 | Device: 1 | Shape: [1,1024] | Autograd: None | 
Tensor 0x61f1e24e5930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24eb230 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e24ecdb0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | Autograd: None | 
Tensor 0x61f1e24ece30 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e24ee820 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e503ec40 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e5073490 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e545b810 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e545c580 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c560 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968c9b0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e968da80 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968dba0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e968eb10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97238e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97242b0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97244a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97261d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9727a60 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97288f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9729590 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972b0a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972c990 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972cd20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d3d0 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e972d450 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972d990 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e972edd0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9730190 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9730d00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97314c0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9732ac0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9734660 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973a580 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e973ac50 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1e973dc50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e973e560 | Refcount: 1 | Device: 1 | Shape: [1024,768] | Autograd: None | 
Tensor 0x61f1e973e730 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97414a0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97422e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9742400 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e9744e80 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9747ab0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e97596e0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e975a690 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e975d740 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e97601e0 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9763170 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e9767370 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1e976c380 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1e978ef00 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead2eb30 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1ead39fe0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ead40600 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f1bc0 | Refcount: 6 | Device: 1 | Shape: [8,1024,768] | Autograd: None | 
Tensor 0x61f1eb0f4b70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5c90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0f5e10 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb0f8e80 | Refcount: 1 | Device: 1 | Shape: [8,1024,3072] | Autograd: None | 
Tensor 0x61f1eb0fa930 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fcd50 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb0fd070 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6bac70 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6cda20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d1940 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d2d10 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6d3160 | Refcount: 1 | Device: 1 | Shape: [768] | Autograd: None | 
Tensor 0x61f1eb6dc5d0 | Refcount: 1 | Device: 1 | Shape: [1] | Autograd: None | 
Tensor 0x61f1eb6dcc20 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6df9f0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6e0690 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6e13d0 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6e2070 | Refcount: 2 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1eb6eb160 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb00ef0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb01b90 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb04280 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0e300 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
Tensor 0x61f1ebb0efa0 | Refcount: 1 | Device: 1 | Shape: [8,1024,1] | GradFn: AllReduceSumBackward | 
==========================================

step     0 | loss: 10.825840 | lr 3.6991e-08 | norm: 0.0000 | dt: 18616.28ms | tok/sec: 3520.36

 microstep = 0
[MEM] Start of micro_step 0 - Used: 6553MB, Free: 5356MB, Tensors: 214


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 



 microstep = 0
[MEM] Start of micro_step 0 - Used: 6790MB, Free: 5110MB, Tensors: 214


 idx shape = [ 8 , 1024 ] 




 Didx shape = [ 8 , 1024 ] 




 Didx size = [ 8192 




 Dpos shape = [ 1 , 1024 ] 




 Dpos size = [ 1024 ] 




 pos_idx shape = [ 1024 ] 


 

 Set Data for pos_emb not done 


  [FWD] pod_emb done
 

 Set Data for idx_emb not done 




 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 6553MB, Free: 5356MB, Tensors: 222


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  0 name = DEmbedding_output
[MEM] After pos_emb - Used: 6553MB, Free: 5356MB, Tensors: 224
  tok_emb device: 0 shape: [8,1024,768]
  pos_emb device: 0 shape: [1,1024,768]


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DEmbeddingVParallel_output
[MEM] After tok_emb - Used: 6822MB, Free: 5078MB, Tensors: 222


 shape = [ 1 , 1024 ] 


 size = 786432 rank =  1 name = DEmbedding_output
[MEM] After pos_emb - Used: 6822MB, Free: 5078MB, Tensors: 224
  tok_emb device: 1 shape: [8,1024,768]
  pos_emb device: 1 shape: [1,1024,768]
[MEM] After tok+pos add - Used: 6585MB, Free: 5324MB, Tensors: 225
[MEM] After tok+pos add - Used: 6854MB, Free: 5046MB, Tensors: 225


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 0 - Used: 6937MB, Free: 4972MB, Tensors: 236
[MEM] After MLP block 0 - Used: 7238MB, Free: 4662MB, Tensors: 236


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 1 - Used: 7321MB, Free: 4588MB, Tensors: 247
[MEM] After MLP block 1 - Used: 7622MB, Free: 4278MB, Tensors: 247


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 2 - Used: 7705MB, Free: 4204MB, Tensors: 258
[MEM] After MLP block 2 - Used: 7974MB, Free: 3926MB, Tensors: 258


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 3 - Used: 8089MB, Free: 3820MB, Tensors: 269
[MEM] After MLP block 3 - Used: 8358MB, Free: 3542MB, Tensors: 269


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 4 - Used: 8473MB, Free: 3436MB, Tensors: 280
[MEM] After MLP block 4 - Used: 8742MB, Free: 3158MB, Tensors: 280


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = DColumnLinear_output


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  0 name = 


 shape = [ 8 , 1024 ] 


 size = 12582912 rank =  1 name = 


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  0 name = DRowLinear_output


 shape = [ 8 , 1024 ] 


 size = 6291456 rank =  1 name = DRowLinear_output
[MEM] After MLP block 5 - Used: 8857MB, Free: 3052MB, Tensors: 291
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 8857MB, Free: 3052MB, Tensors: 291
[MEM] After MLP block 5 - Used: 9126MB, Free: 2774MB, Tensors: 291
  [FWD] All MLP blocks done
[MEM] Before ln_f - Used: 9126MB, Free: 2774MB, Tensors: 291
[MEM] After ln_f - Used: 8889MB, Free: 3020MB, Tensors: 296
[MEM] Before lm_head - Used: 8889MB, Free: 3020MB, Tensors: 296
[MEM] After ln_f - Used: 9158MB, Free: 2742MB, Tensors: 296
[MEM] Before lm_head - Used: 9158MB, Free: 2742MB, Tensors: 296


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  0 name = lm_head_sharded_output


 shape = [ 8 , 1024 ] 


 size = 412090368 rank =  1 name = lm_head_sharded_output
[MEM] After lm_head - Used: 9689MB, Free: 2220MB, Tensors: 298
[MEM] After lm_head - Used: 9958MB, Free: 1942MB, Tensors: 298
CUDA Allocation Failed: out of memory(requested 786 MB
CUDA Allocation Failed: out of memory(requested 786 MB
ERROR: CUDA allcation failed
ERROR: CUDA allcation failed
--------------------------------------------------------------------------
prterun detected that one or more processes exited with non-zero status,
thus causing the job to be terminated. The first process to do so was:

   Process name: [prterun-blubridge25-MS-7E06-64037@1,0]
   Exit code:    1
--------------------------------------------------------------------------
